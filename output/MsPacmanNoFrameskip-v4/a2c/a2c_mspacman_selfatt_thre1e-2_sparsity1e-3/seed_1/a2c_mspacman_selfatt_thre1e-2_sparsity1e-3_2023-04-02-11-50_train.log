2023-04-02 11:50:04,375 Namespace(TEST_MODEL_FILE=None, cfg='experiments/atari/a2c_mspacman_selfatt_thre1e-2_sparsity1e-3.yaml', eval_only=False, render=False, seed=1)
2023-04-02 11:50:04,377 {'AUTO_RESUME': False,
 'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True},
 'DATASET': {'BRIGHTNESS_FACTOR': 0.0,
             'COLOR_RGB': True,
             'CONTRAST_FACTOR': 0.0,
             'DATASET': 'mpii',
             'GRAYSCALE': True,
             'HISTORY_INPUT': False,
             'HUE_FACTOR': 0.0,
             'HYBRID': False,
             'ROOT': '',
             'SAMPLE_2_FRAME': False,
             'SAMPLE_2_FRAME_OFFSET': 0,
             'SAMPLE_STEP': 1,
             'SAT_FACTOR': 0.0,
             'TEST_SET': 'valid',
             'TRAIN_SET': 'train',
             'TRANSFORM': False},
 'DATA_DIR': '',
 'DEBUG': {'DEBUG': False},
 'GPUS': '0',
 'LOG_DIR': 'log',
 'MODEL': {'HEATMAP_SIZE': [64, 64],
           'IGNORE_BACKGROUND': False,
           'IMAGE_SIZE': array([84, 84]),
           'INIT_WEIGHTS': True,
           'NAME': 'a2c',
           'PRETRAINED': '',
           'SIGMA': 1},
 'MODEL_FILE': '',
 'OUTPUT_DIR': 'output',
 'PIN_MEMORY': True,
 'PRINT_FREQ': 100,
 'RESUME': False,
 'SELFSUP_ATTENTION': {'AUTOENCODER_LOSS': True,
                       'BLOCK_IMAGE_FEAT_GRADIENT': False,
                       'DECODER_WITH_SIGMOID': True,
                       'GAUSS_STD': 0.1,
                       'HEATMAP_SPARSITY_LOSS': True,
                       'HEATMAP_SPARSITY_LOSS_WEIGHT': 0.001,
                       'KEYPOINTER_CLS_AGNOSTIC': True,
                       'NUM_KEYPOINTS': 7,
                       'RECONSTRUCT_LOSS_THRESHOLD': 0.01,
                       'SHARE_PARAMETERS': False,
                       'USE_INSTANCE_NORM': False,
                       'USE_LAYER_NORM': False},
 'TEST': {'BATCH_SIZE_PER_GPU': 32, 'MODEL_FILE': ''},
 'TRAIN': {'BATCH_SIZE_PER_GPU': 32,
           'BEGIN_EPOCH': 0,
           'CHECKPOINT': '',
           'END_EPOCH': 140,
           'GAMMA1': 0.99,
           'GAMMA2': 0.0,
           'LR': 0.001,
           'LR_FACTOR': 0.1,
           'LR_STEP': [90, 110],
           'MOMENTUM': 0.9,
           'NESTEROV': False,
           'OPTIMIZER': 'adam',
           'RESUME': False,
           'SHUFFLE': True,
           'WD': 0.0001},
 'WORKERS': 4,
 'algo': 'a2c',
 'alpha': 0.99,
 'block_selfsup_attention_grad': False,
 'bottom_up_downsample_mask': False,
 'bottom_up_downsample_mask_stride1': False,
 'bottom_up_form_num_of_objects': 10,
 'bottom_up_form_objects': False,
 'cuda': True,
 'cuda_deterministic': False,
 'entropy_coef': 0.01,
 'env_name': 'MsPacmanNoFrameskip-v4',
 'eps': 1e-05,
 'eval_interval': 1250,
 'feat_add_selfsup_attention': True,
 'feat_from_selfsup_attention': False,
 'feat_mul_selfsup_attention_mask': True,
 'feat_mul_selfsup_attention_mask_residual': False,
 'feat_pool_with_selfsup_attention': False,
 'fix_feature': False,
 'gae_lambda': 0.95,
 'gail': False,
 'gail_batch_size': 128,
 'gail_epoch': 5,
 'gail_experts_dir': './gail_experts',
 'gamma': 0.99,
 'gaussian_std': 0.1,
 'hidden_size': 512,
 'log_interval': 250,
 'lr': 0.0007,
 'mask_threshold': -1.0,
 'max_grad_norm': 0.5,
 'no_cuda': False,
 'num_env_steps': 10000000,
 'num_processes': 1,
 'num_steps': 5,
 'ppo_epoch': 4,
 'recurrent_policy': False,
 'resized_size': 84,
 'save_dir': './trained_models/',
 'save_interval': 1250,
 'seed': 1,
 'selfsup_attention_feat_load_pretrained': True,
 'selfsup_attention_feat_masked': True,
 'selfsup_attention_feat_masked_residual': False,
 'selfsup_attention_fix': False,
 'selfsup_attention_fix_keypointer': False,
 'selfsup_attention_image_feat_only': False,
 'selfsup_attention_keyp_maps_pool': True,
 'selfsup_attention_multiframe': False,
 'selfsup_attention_pretrain': '',
 'sep_bg_fg_feat': False,
 'temperature': 0.07,
 'train_selfsup_attention': True,
 'train_selfsup_attention_batch_size': 256,
 'train_selfsup_attention_buffer_size': 10000,
 'use_gae': False,
 'use_layer_norm': False,
 'use_linear_lr_decay': False,
 'use_proper_time_limits': False,
 'value_loss_coef': 0.5,
 'weight_decay': 0.0}
2023-04-02 11:50:38,493 Updates 2250, num timesteps 11255
selfsup attention loss 6.23617

2023-04-02 11:50:45,679 Namespace(TEST_MODEL_FILE=None, cfg='experiments/atari/a2c_mspacman_selfatt_thre1e-2_sparsity1e-3.yaml', eval_only=False, render=False, seed=1)
2023-04-02 11:50:45,680 {'AUTO_RESUME': False,
 'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True},
 'DATASET': {'BRIGHTNESS_FACTOR': 0.0,
             'COLOR_RGB': True,
             'CONTRAST_FACTOR': 0.0,
             'DATASET': 'mpii',
             'GRAYSCALE': True,
             'HISTORY_INPUT': False,
             'HUE_FACTOR': 0.0,
             'HYBRID': False,
             'ROOT': '',
             'SAMPLE_2_FRAME': False,
             'SAMPLE_2_FRAME_OFFSET': 0,
             'SAMPLE_STEP': 1,
             'SAT_FACTOR': 0.0,
             'TEST_SET': 'valid',
             'TRAIN_SET': 'train',
             'TRANSFORM': False},
 'DATA_DIR': '',
 'DEBUG': {'DEBUG': False},
 'GPUS': '0',
 'LOG_DIR': 'log',
 'MODEL': {'HEATMAP_SIZE': [64, 64],
           'IGNORE_BACKGROUND': False,
           'IMAGE_SIZE': array([84, 84]),
           'INIT_WEIGHTS': True,
           'NAME': 'a2c',
           'PRETRAINED': '',
           'SIGMA': 1},
 'MODEL_FILE': '',
 'OUTPUT_DIR': 'output',
 'PIN_MEMORY': True,
 'PRINT_FREQ': 100,
 'RESUME': False,
 'SELFSUP_ATTENTION': {'AUTOENCODER_LOSS': True,
                       'BLOCK_IMAGE_FEAT_GRADIENT': False,
                       'DECODER_WITH_SIGMOID': True,
                       'GAUSS_STD': 0.1,
                       'HEATMAP_SPARSITY_LOSS': True,
                       'HEATMAP_SPARSITY_LOSS_WEIGHT': 0.001,
                       'KEYPOINTER_CLS_AGNOSTIC': True,
                       'NUM_KEYPOINTS': 7,
                       'RECONSTRUCT_LOSS_THRESHOLD': 0.01,
                       'SHARE_PARAMETERS': False,
                       'USE_INSTANCE_NORM': False,
                       'USE_LAYER_NORM': False},
 'TEST': {'BATCH_SIZE_PER_GPU': 32, 'MODEL_FILE': ''},
 'TRAIN': {'BATCH_SIZE_PER_GPU': 32,
           'BEGIN_EPOCH': 0,
           'CHECKPOINT': '',
           'END_EPOCH': 140,
           'GAMMA1': 0.99,
           'GAMMA2': 0.0,
           'LR': 0.001,
           'LR_FACTOR': 0.1,
           'LR_STEP': [90, 110],
           'MOMENTUM': 0.9,
           'NESTEROV': False,
           'OPTIMIZER': 'adam',
           'RESUME': False,
           'SHUFFLE': True,
           'WD': 0.0001},
 'WORKERS': 4,
 'algo': 'a2c',
 'alpha': 0.99,
 'block_selfsup_attention_grad': False,
 'bottom_up_downsample_mask': False,
 'bottom_up_downsample_mask_stride1': False,
 'bottom_up_form_num_of_objects': 10,
 'bottom_up_form_objects': False,
 'cuda': True,
 'cuda_deterministic': False,
 'entropy_coef': 0.01,
 'env_name': 'MsPacmanNoFrameskip-v4',
 'eps': 1e-05,
 'eval_interval': 1250,
 'feat_add_selfsup_attention': True,
 'feat_from_selfsup_attention': False,
 'feat_mul_selfsup_attention_mask': True,
 'feat_mul_selfsup_attention_mask_residual': False,
 'feat_pool_with_selfsup_attention': False,
 'fix_feature': False,
 'gae_lambda': 0.95,
 'gail': False,
 'gail_batch_size': 128,
 'gail_epoch': 5,
 'gail_experts_dir': './gail_experts',
 'gamma': 0.99,
 'gaussian_std': 0.1,
 'hidden_size': 512,
 'log_interval': 250,
 'lr': 0.0007,
 'mask_threshold': -1.0,
 'max_grad_norm': 0.5,
 'no_cuda': False,
 'num_env_steps': 500000,
 'num_processes': 1,
 'num_steps': 5,
 'ppo_epoch': 4,
 'recurrent_policy': False,
 'resized_size': 84,
 'save_dir': './trained_models/',
 'save_interval': 1250,
 'seed': 1,
 'selfsup_attention_feat_load_pretrained': True,
 'selfsup_attention_feat_masked': True,
 'selfsup_attention_feat_masked_residual': False,
 'selfsup_attention_fix': False,
 'selfsup_attention_fix_keypointer': False,
 'selfsup_attention_image_feat_only': False,
 'selfsup_attention_keyp_maps_pool': True,
 'selfsup_attention_multiframe': False,
 'selfsup_attention_pretrain': '',
 'sep_bg_fg_feat': False,
 'temperature': 0.07,
 'train_selfsup_attention': True,
 'train_selfsup_attention_batch_size': 256,
 'train_selfsup_attention_buffer_size': 10000,
 'use_gae': False,
 'use_layer_norm': False,
 'use_linear_lr_decay': False,
 'use_proper_time_limits': False,
 'value_loss_coef': 0.5,
 'weight_decay': 0.0}
2023-04-02 11:51:19,661 Updates 2250, num timesteps 11255
selfsup attention loss 6.23621

2023-04-02 11:51:40,559 Updates 2500, num timesteps 12505
selfsup attention loss 6.23664

2023-04-02 11:52:01,234 Updates 2750, num timesteps 13755
selfsup attention loss 6.17895

2023-04-02 11:52:21,964 Updates 3000, num timesteps 15005
selfsup attention loss 5.76608

2023-04-02 11:52:42,646 Updates 3250, num timesteps 16255
selfsup attention loss 5.66252

2023-04-02 11:53:03,413 Updates 3500, num timesteps 17505
selfsup attention loss 5.54085

2023-04-02 11:53:23,970 Updates 3750, num timesteps 18755
selfsup attention loss 5.45094

2023-04-02 11:53:44,740 Updates 4000, num timesteps 20005
selfsup attention loss 5.41650

2023-04-02 11:54:05,261 Updates 4250, num timesteps 21255
selfsup attention loss 5.25247

2023-04-02 11:54:25,837 Updates 4500, num timesteps 22505
selfsup attention loss 5.48426

2023-04-02 11:54:47,415 Updates 4750, num timesteps 23755
selfsup attention loss 5.49623

2023-04-02 11:55:07,935 Updates 5000, num timesteps 25005
selfsup attention loss 5.45053

2023-04-02 11:55:28,395 Updates 5250, num timesteps 26255
selfsup attention loss 5.12973

2023-04-02 11:55:49,390 Updates 5500, num timesteps 27505
selfsup attention loss 5.24426

2023-04-02 11:56:11,731 Updates 5750, num timesteps 28755
selfsup attention loss 5.26571

2023-04-02 11:56:35,545 Updates 6000, num timesteps 30005
selfsup attention loss 4.99259

2023-04-02 11:56:57,704 Updates 6250, num timesteps 31255
selfsup attention loss 4.95054

2023-04-02 11:57:21,746 Updates 6500, num timesteps 32505
selfsup attention loss 5.15766

2023-04-02 11:57:45,304 Updates 6750, num timesteps 33755
selfsup attention loss 5.20138

2023-04-02 11:58:06,486 Updates 7000, num timesteps 35005
selfsup attention loss 5.22430

2023-04-02 11:58:27,124 Updates 7250, num timesteps 36255
selfsup attention loss 5.10226

